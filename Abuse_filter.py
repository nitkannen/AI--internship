# -*- coding: utf-8 -*-
"""abuse_filter_function.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rFCjCmK0W7IX1vZ9Wu0tIJ8cmxX7OEct
"""

#imports

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Model
from keras.layers import Bidirectional,LSTM,Dense,Embedding,Input,GlobalMaxPool1D,Dropout
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC

def load_data():
  df = pd.read_csv('train.csv',engine='python',error_bad_lines=False)
  #df.head()
  #len(df)
  #df['comment_text'].isnull().sum()
  train_text = df['comment_text'].fillna('NULL').values
  #train_text.shape
  target_columns = ['toxic', 'severe_toxic', 'obscene', 'threat',
       'insult', 'identity_hate']
  target= df[target_columns].values
  #print(target.shape)

df = pd.read_csv('train.csv',engine='python',error_bad_lines=False)

##df.head()

len(df)

df['comment_text'].isnull().sum()

train_text = df['comment_text'].fillna('NULL').values

train_text.shape



def get_embedding():   ## initialises pre- trained word embeddings
  word2vec = {}
  with open('glove.6B.100d.txt',encoding = 'utf8') as f:
    for lines in f:
        val = lines.split()
        word = val[0]
        vec = np.asarray(val[1:],dtype = 'float32')
        word2vec[word] = vec
        #print(len(word2vec))
        
        

def initialise():   ## Hyperparameters and constants
  max_length = max([len(s) for s in train_tokens])
  MAX_VOCAB = 400000
  MAX_SEQUENCE_LENGTH = 100
  EMBEDDING_DIMENSION = 100
  
  

def tokenization_padding():  ## Tokenisation and padding of the input sentences
  tokenizer = Tokenizer(filters = '#$%&()*+,-[\\]^_`{|}~')
  tokenizer.fit_on_texts(train_text)
  train_tokens = tokenizer.texts_to_sequences(train_text)
  #len(tokenizer.index_word)
  train_tokens_pad = pad_sequences(train_tokens,maxlen = MAX_SEQUENCE_LENGTH,truncating= 'post')
  #train_tokens_pad.shape
  
  

def visualise():
  plt.figure(figsize = (10,6))
  plt.hist(df['comment_text'].apply(lambda x : len(x)),bins = 50)
  
  

def embedding():
    """
    creates the embedding matrix with the word vectors
    """
  embedding_matrix = np.zeros((MAX_VOCAB,EMBEDDING_DIMENSION))
  for i,j in tokenizer.word_index.items():
    vec = word2vec.get(i)
    if vec is not None:
        if j<MAX_VOCAB:
            embedding_matrix[j,:] = vec



  #embedding_matrix.shape

def model_architecture_lstm():
  """
  This function creates the model architecture for the LSTM based abusive comment
  classifier
  """
    
  embedding_layer = Embedding((MAX_VOCAB),100,weights = [embedding_matrix], trainable = True )
  chat = Input(shape = (MAX_SEQUENCE_LENGTH,))
  x = embedding_layer(chat)
  #x = Dropout(0.2)(x)
  x = Bidirectional(LSTM(100,dropout = 0.3,recurrent_dropout = 0.2,return_sequences = True))(x)
  x = Dense(40, activation = 'relu')(x)
  x = Dropout(0.2)(x)
  x = Bidirectional(LSTM(100,dropout = 0.25,recurrent_dropout = 0.2,return_sequences = True))(x)
  x = GlobalMaxPool1D()(x)
  output = Dense(6,activation = 'sigmoid')(x)
  
  

  ##model = Model(input = chat, output = output)

def create_model_lstm():
    
  #Hyperparameters used
  #Epochs = 3/4
  #batch_size = 256
  #optimizer = adam
  #loss = binary_crossentropy
  model = Model(inputs = chat,outputs = output)
  model.compile(optimizer = 'adam',loss = 'binary_crossentropy', metrics = ['accuracy'])
 #model.summary()




def train_model_lstm():
  s = model.fit(train_tokens_pad[:95000],target[:95000],batch_size = 256,epochs= 3, validation_split = 0.09)




def model_perfomance_lstm():
  plt.figure(figsize = (10,6))
  plt.plot(r.history['accuracy'])
  plt.plot(r.history['val_accuracy'])
  
  

def process_input_string(new_string):
    
    """
    This function is to pre-process the input string for test cases with
    the same preprocessing applied to training sentences
    """
    string_tokens = tokenizer.texts_to_sequences([new_string])
    #string_tokens.shape
    string_tokens_pad = pad_sequences(string_tokens,maxlen = MAX_SEQUENCE_LENGTH)
    #string_tokens_pad.shape
    return string_tokens_pad



def pred_lstm(new_string):
    string_tokens_pad = process_input_string(new_string)
    pred = model.predict(string_tokens_pad)
    abuse = pred
    #abuse.shape
    
    return abuse



"""Naive Bayes LinearSVC() linear model""" 

""" In this model we create an ensemble method between a LSTM based deep learning 
model and a Naive Bayes LinearSVC() ML model
"""

def preprocess_nb():
  """
  Vectorizes the input data. TF_IDF = term_frequency*(1/document frequency). This converts
  input data into a vector
  """
  vec = TfidfVectorizer(ngram_range=(1,2), 
               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,
               smooth_idf=1, sublinear_tf=1 )
  x = vec.fit_transform(train_text)


def pr(y_i, y):
    p = x[y==y_i].sum(0)
    return (p+1) / ((y==y_i).sum()+1)


def get_train_features(y):
    
    y = y.values
    r = np.log(pr(1,y) / pr(0,y))
    #m = LogisticRegression(C=4, dual=True)
    x_nb = x.multiply(r)
    return x_nb,r

def fit_threat_nb(): ## fitting the model fot threat data
    
  m_threat = LinearSVC()
  x_nb,r_threat = get_train_features(df['threat'])
  m_threat.fit(x_nb,df['threat'])
  
  

def predict_threat_nb(input_string):
    
    input_string = vec.fit([input_string])
    input_feature = input_string.multiply(r_threat)
    pred = m_threat.predict(input_feature)
    
    return pred



def fit_identityhate_nb(): ## fitting the model for identity_hate data
    
  m_identity_hate = LinearSVC()
  x_nb,r_identity_hate = get_train_features(df['identity_hate'])
  m_identity_hate.fit(x_nb,df['identity_hate'])



def predict_identity_hate_nb(input_string):
    input_string = vec.fit([input_string])
    input_feature = input_string.multiply(r_identity_hate)
    pred = m_identity_hate.predict(input_feature)
    
    return pred



def driver_function( chat_string ):
  """
  This is the driver function that needs to be run. It calls all the functions
  and predicts the probability of toxicity
  """    
    
  flag = 0
    
    
  load_data() # Gets training set and targets

  get_embedding() # gets the word vectors

  initialise()  # initialise params

  tokenization_padding() #tokenized and padded texts

  embedding()  # creates embedding matrix

  model_architecture_lstm() #lstm model builder

  create_model_lstm()  #initialise model with hyperparams

  train_model_lstm()  
   # train lstm model approx 1 hour,
  lstm_prediction = pred_lstm(chat_string)
  #lstm_prediction.shape

  threat_prediction = predict_threat_nb(chat_string)
  #threat_prediction.shape

  identity_hate_prediction = predict_identity_hate_nb(input_string)
  #identity_hate_prediction.shape

  final_prediction = lstm_prediction
  #final_prediction.shape

  final_prediction[:,3][0] =lstm_prediction[:,3][0]*0.4 + threat_prediction[0]*0.6
  #final_prediction

  final_prediction[:,5][0] =lstm_prediction[:,5][0]*0.45 + identity_hate_prediction[0]*0.65
  #final_prediction
  
  target_columns = ['toxic', 'severe_toxic', 'obscene', 'threat',
       'insult', 'identity_hate']

  #final printing of of results     
  for i,j in enumerate(final_prediction[0]):
    if j > 0.65:
      flag = 1
      #print("The chat has "+ str(target_columns[i]))
      if(j>0.95):
        j = j - 0.1
      #print("The chat has "+ str(target_columns[i]) "  ,Probability:" + str(j-0.1))
      print("The chat has "+ str(target_columns[i]) +"  Probability:" +str(j))
      print('\n')

  if (flag == 0):
    print('safe') 
      
# Load the req models and packages 

MAX_VOCAB = 400000
MAX_SEQUENCE_LENGTH = 100
EMBEDDING_DIMENSION = 100

with open('tokenizer.sav','rb') as f:
    tokenizer = pickle.load(f)

with open('vec.sav','rb') as f:
    vec = pickle.load(f)

with open('lstm1_model.sav','rb') as f:
    model = pickle.load(f)

with open('model_hate.sav','rb') as f:
    m_identity_hate = pickle.load(f)


with open('model_threat.sav','rb') as f:
    m_threat = pickle.load(f)
    
with open('r_hate.sav','rb') as f:
    r_identity_hate = pickle.load(f)

with open('r_threat.sav','rb') as f:
    r_threat = pickle.load(f)
      
      
 # Example usage
 #chat = "     insert chat   "
#driver_function(chat)     
 #chat_string = " It wasnt the best date ever, never mind you were fine" Not toxic..
 #chat_string = "That was the worst date of my life" Not toxic
 #chat_string = " lololol, how can you be so dumb dude. It wasnt what i meant when i said that" Not that toxic..
 #chat_string = "That was the worst date of my life"
 #chat_string = " You better accept my match, my father is a rowdy head and I can ruin your career if you dont and you will regret it and put your family in danger" 
 #chat_string = "You dont seem to be that smart, like you act."
      
      